2024-08-09 17:48:36,523 - DEBUG - Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU
2024-08-09 17:48:36,523 - INFO - Loading faiss with AVX2 support.
2024-08-09 17:48:36,619 - INFO - Successfully loaded faiss with AVX2 support.
2024-08-09 17:48:36,685 - INFO - LLM Loaded
2024-08-09 17:48:36,687 - INFO - Use pytorch device_name: cpu
2024-08-09 17:48:36,687 - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5
2024-08-09 17:48:36,692 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-08-09 17:48:36,942 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/modules.json HTTP/11" 200 0
2024-08-09 17:48:37,163 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json HTTP/11" 200 0
2024-08-09 17:48:37,395 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/README.md HTTP/11" 200 0
2024-08-09 17:48:37,602 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/modules.json HTTP/11" 200 0
2024-08-09 17:48:37,814 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/sentence_bert_config.json HTTP/11" 200 0
2024-08-09 17:48:38,017 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/config.json HTTP/11" 200 0
2024-08-09 17:48:38,910 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-08-09 17:48:39,223 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en-v1.5/revision/main HTTP/11" 200 148373
2024-08-09 17:48:39,616 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en-v1.5 HTTP/11" 200 148373
2024-08-09 17:48:39,733 - INFO - Embedding Model Loaded
2024-08-09 17:48:42,367 - INFO - Loading llama_index.vector_stores.faiss.base from ./storage\default__vector_store.json.
2024-08-09 17:51:16,155 - INFO - LLM Loaded
2024-08-09 17:51:16,156 - INFO - Use pytorch device_name: cpu
2024-08-09 17:51:16,156 - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5
2024-08-09 17:51:16,373 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/modules.json HTTP/11" 200 0
2024-08-09 17:51:16,571 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json HTTP/11" 200 0
2024-08-09 17:51:16,775 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/README.md HTTP/11" 200 0
2024-08-09 17:51:17,031 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/modules.json HTTP/11" 200 0
2024-08-09 17:51:17,228 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/sentence_bert_config.json HTTP/11" 200 0
2024-08-09 17:51:17,433 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/config.json HTTP/11" 200 0
2024-08-09 17:51:17,923 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en-v1.5/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-08-09 17:51:18,170 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en-v1.5/revision/main HTTP/11" 200 148373
2024-08-09 17:51:18,504 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en-v1.5 HTTP/11" 200 148373
2024-08-09 17:51:18,611 - INFO - Embedding Model Loaded
2024-08-09 17:51:19,917 - INFO - Loading llama_index.vector_stores.faiss.base from ./storage\default__vector_store.json.
2024-08-09 17:56:56,937 - INFO - Loading llama_index.vector_stores.faiss.base from ./storage\default__vector_store.json.
