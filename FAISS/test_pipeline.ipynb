{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdef424c-7135-4387-899b-7ea14f8d7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  ingestion_pipeline_creator import run_pipeline , build_pipeline , load_model\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import logging\n",
    "import logging.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb3b4ec-994b-4399-ba4c-5337a9d2fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"test.log\" , level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "logger = logging.getLogger('simpleExample')\n",
    "\n",
    "llm , embed_model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b787946-bc5f-472d-8df4-25409036c1bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\logging\\__init__.py\", line 1079, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\logging\\__init__.py\", line 923, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\logging\\__init__.py\", line 659, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\logging\\__init__.py\", line 363, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Temp\\ipykernel_22692\\2575014573.py\", line 1, in <module>\n",
      "    query_engine , pipeline = build_pipeline(llm , embed_model)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\FAISS\\ingestion_pipeline_creator.py\", line 73, in build_pipeline\n",
      "Message: 'Built Transformations'\n",
      "Arguments: ([SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x000002269E2A7B50>, id_func=<function default_id_func at 0x00000226601E6AF0>, chunk_size=1024, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?'), TitleExtractor(is_text_node_only=False, show_progress=True, metadata_mode=<MetadataMode.EMBED: 'embed'>, node_text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n', disable_template_rewrite=False, in_place=True, num_workers=4, llm=Groq(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x000002262FA21700>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x0000022660107940>, completion_to_prompt=<function default_completion_to_prompt at 0x00000226601BA820>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='llama3-70b-8192', temperature=0.1, max_tokens=None, logprobs=None, top_logprobs=0, additional_kwargs={}, max_retries=3, timeout=60.0, default_headers=None, reuse_client=True, api_key='', api_base='https://api.groq.com/openai/v1', api_version='', strict=False, context_window=3900, is_chat_model=True, is_function_calling_model=True, tokenizer=None), nodes=5, node_template='Context: {context_str}. Give a title that summarizes all of the unique entities, titles or themes found in the context. Title: ', combine_template='{context_str}. Based on the above candidate titles and content, what is the comprehensive title for this document? Title: '), SummaryExtractor(is_text_node_only=True, show_progress=True, metadata_mode=<MetadataMode.EMBED: 'embed'>, node_text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n', disable_template_rewrite=False, in_place=True, num_workers=4, llm=Groq(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x000002262FA21700>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x0000022660107940>, completion_to_prompt=<function default_completion_to_prompt at 0x00000226601BA820>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='llama3-70b-8192', temperature=0.1, max_tokens=None, logprobs=None, top_logprobs=0, additional_kwargs={}, max_retries=3, timeout=60.0, default_headers=None, reuse_client=True, api_key='', api_base='https://api.groq.com/openai/v1', api_version='', strict=False, context_window=3900, is_chat_model=True, is_function_calling_model=True, tokenizer=None), summaries=['self'], prompt_template='Here is the content of the section:\\n{context_str}\\n\\nSummarize the key topics and entities of the section. \\nSummary: '), SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")],)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Temp\\ipykernel_22692\\2575014573.py\", line 1, in <module>\n",
      "    query_engine , pipeline = build_pipeline(llm , embed_model)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\FAISS\\ingestion_pipeline_creator.py\", line 75, in build_pipeline\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\llama_index\\vector_stores\\faiss\\base.py\", line 81, in from_persist_dir\n",
      "    return cls.from_persist_path(persist_path=persist_path, fs=None)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\llama_index\\vector_stores\\faiss\\base.py\", line 100, in from_persist_path\n",
      "    faiss_index = faiss.read_index(persist_path)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\faiss\\swigfaiss_avx2.py\", line 10409, in read_index\n",
      "    return _swigfaiss_avx2.read_index(*args)\n",
      "RuntimeError: Error in Index *__cdecl faiss::read_index(IOReader *, int) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\index_read.cpp:1056: Index type 0x6d65227b (\"{\"em\") not recognized\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1155, in get_records\n",
      "    FrameInfo(\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 780, in __init__\n",
      "    ix = inspect.getsourcelines(frame)\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\inspect.py\", line 994, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\inspect.py\", line 835, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "query_engine , pipeline = build_pipeline(llm , embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "087c2b71-cab8-4b1a-a2b3-5b7eaf183505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "\n",
    "from llama_index.core.ingestion import (\n",
    "    DocstoreStrategy,\n",
    "    IngestionPipeline,\n",
    "    IngestionCache,\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import logging\n",
    "import logging.config\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.core.extractors import TitleExtractor, SummaryExtractor\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "logging.basicConfig(filename=\"built.log\" , level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "load_dotenv() \n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")  \n",
    "\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    ")\n",
    "\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c6e80a3-1e3b-4c9b-b10c-d442b653de40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\logging\\__init__.py\", line 1079, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\logging\\__init__.py\", line 923, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\logging\\__init__.py\", line 659, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\logging\\__init__.py\", line 363, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\hardi\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hardi\\AppData\\Local\\Temp\\ipykernel_22692\\3711009528.py\", line 12, in <module>\n",
      "    logger.critical('Built Transformations' , transformations)\n",
      "Message: 'Built Transformations'\n",
      "Arguments: ([SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000226A0484820>, id_func=<function default_id_func at 0x00000226601E6AF0>, chunk_size=1024, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?'), TitleExtractor(is_text_node_only=False, show_progress=True, metadata_mode=<MetadataMode.EMBED: 'embed'>, node_text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n', disable_template_rewrite=False, in_place=True, num_workers=4, llm=Groq(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x000002262FA21700>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x0000022660107940>, completion_to_prompt=<function default_completion_to_prompt at 0x00000226601BA820>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='llama3-70b-8192', temperature=0.1, max_tokens=None, logprobs=None, top_logprobs=0, additional_kwargs={}, max_retries=3, timeout=60.0, default_headers=None, reuse_client=True, api_key='', api_base='https://api.groq.com/openai/v1', api_version='', strict=False, context_window=3900, is_chat_model=True, is_function_calling_model=True, tokenizer=None), nodes=5, node_template='Context: {context_str}. Give a title that summarizes all of the unique entities, titles or themes found in the context. Title: ', combine_template='{context_str}. Based on the above candidate titles and content, what is the comprehensive title for this document? Title: '), SummaryExtractor(is_text_node_only=True, show_progress=True, metadata_mode=<MetadataMode.EMBED: 'embed'>, node_text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n', disable_template_rewrite=False, in_place=True, num_workers=4, llm=Groq(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x000002262FA21700>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x0000022660107940>, completion_to_prompt=<function default_completion_to_prompt at 0x00000226601BA820>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='llama3-70b-8192', temperature=0.1, max_tokens=None, logprobs=None, top_logprobs=0, additional_kwargs={}, max_retries=3, timeout=60.0, default_headers=None, reuse_client=True, api_key='', api_base='https://api.groq.com/openai/v1', api_version='', strict=False, context_window=3900, is_chat_model=True, is_function_calling_model=True, tokenizer=None), summaries=['self'], prompt_template='Here is the content of the section:\\n{context_str}\\n\\nSummarize the key topics and entities of the section. \\nSummary: '), SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")],)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error in Index *__cdecl faiss::read_index(IOReader *, int) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\index_read.cpp:1056: Index type 0x6d65227b (\"{\"em\") not recognized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22692\\3711009528.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m transformations = [\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mSentenceSplitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_overlap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     TitleExtractor(\n\u001b[0;32m     17\u001b[0m         \u001b[0mllm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMetadataMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEMBED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\llama_index\\vector_stores\\faiss\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cls, persist_dir, fs)\u001b[0m\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# only support local storage for now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLocalFileSystem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FAISS only supports local storage for now.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_persist_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpersist_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpersist_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\llama_index\\vector_stores\\faiss\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cls, persist_path, fs)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpersist_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"No existing {__name__} found at {persist_path}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loading {__name__} from {persist_path}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mfaiss_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpersist_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaiss_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfaiss_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Hardik_stuff\\Acumen_Enginering\\VENV\\lib\\site-packages\\faiss\\swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m  10408\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10409\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Error in Index *__cdecl faiss::read_index(IOReader *, int) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\index_read.cpp:1056: Index type 0x6d65227b (\"{\"em\") not recognized"
     ]
    }
   ],
   "source": [
    "\n",
    "transformations = [\n",
    "    SentenceSplitter(chunk_size=1024, chunk_overlap=20),\n",
    "    TitleExtractor(\n",
    "        llm=llm, metadata_mode=MetadataMode.EMBED, num_workers=4\n",
    "    ),\n",
    "    SummaryExtractor(\n",
    "        llm=llm, metadata_mode=MetadataMode.EMBED, num_workers=4\n",
    "    ),\n",
    "    embed_model\n",
    "]\n",
    "\n",
    "logger.critical('Built Transformations' , transformations)\n",
    "\n",
    "vector_store = FaissVectorStore.from_persist_dir(\"./storage\")\n",
    "logger.info('Built Vector Store' , vector_store)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=\"./storage\"\n",
    ")\n",
    "logger.info('Built Vector Store' , vector_store)\n",
    "\n",
    "index = load_index_from_storage(storage_context=storage_context)\n",
    "logger.info('Built Vector Store' , index)\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "logger.critical(\"Built docstore\" , docstore)\n",
    "\n",
    "pipeline = IngestionPipeline(transformations=transformations ,\n",
    "                        docstore=docstore,\n",
    "                        vector_store=vector_store,\n",
    "                        docstore_strategy=DocstoreStrategy.UPSERTS\n",
    "                        )\n",
    "\n",
    "logger.critical(\"Built the pipeline\" , pipeline)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580fb7c-304a-453d-91c0-88bd4dacda76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224b3ad-e2e1-4d89-82b1-096b94a9475a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6250e3d-bee2-48b8-9578-cb5abcf5a7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748dd313-8076-4b41-b7bb-32548b2fc2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ec439-fd95-415a-af15-3d740c550dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb7d92-6b6a-419b-ad35-06ab4abf4ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45e41f-e914-4e97-9e99-d3786df4677c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc652d-ac76-4c49-8fa9-eeb73f016a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7cd42b-f552-41da-ad29-cfd344050f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d454eb1-0d7a-4fe4-9179-9732fad37390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6c66a-6477-4793-924b-c6a79e4c068a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966a75f-5cbf-4a28-8f26-321717d2aac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8cb42e-275c-4724-82b3-6ebc49b5dcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8091e-0850-4439-817d-3edf8f26fe98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c17f7-008e-40a0-a808-e46a3129147d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252e9d52-3c39-4098-8cfb-efc5e490ea6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
